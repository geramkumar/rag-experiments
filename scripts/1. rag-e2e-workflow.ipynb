{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bfe633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9be2f114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/dataengineering.txt'}, page_content='Agentic AI refers to intelligent systems that can autonomously plan, decide, and execute actions toward specific predefined goals without constant human supervision.\\nUnlike traditional software programs, an agent observes its environment, reasons about possible outcomes, and selects the most appropriate action dynamically.\\nThe main purpose of agentic systems is reducing manual effort while improving decision-making efficiency in complex workflows.\\nThese systems typically include memory components, reasoning engines, and the ability to call external tools or APIs.\\nAn AI agent can interact with databases, web services, or enterprise applications to complete assigned objectives.\\nPlanning capabilities allow the agent to decompose large tasks into smaller manageable steps before execution.\\nReactive agents respond immediately to stimuli, whereas deliberative agents evaluate multiple possibilities before acting.\\nMulti-agent architectures enable several autonomous entities to collaborate and solve shared organizational problems effectively.\\nThe concept of ＡＩ-driven autonomy is transforming how businesses design intelligent automation solutions.\\nAgentic paradigms represent a shift from passive prediction models toward proactive digital assistants capable of independent execution.\\n\\nLangChain is an application development framework created to simplify building solutions powered by large language models.\\nIt provides abstractions for prompt templates, memory management, and integration with external tools and services.\\nThe primary purpose of LangChain is orchestrating multi-step reasoning workflows that involve language model interaction.\\nChains combine multiple components sequentially so that outputs from one step become inputs for another step.\\nAgents in LangChain can analyze user queries and determine which tool should be invoked dynamically.\\nRetrievers connect to vector databases, enabling semantic search instead of relying only on keyword matching.\\nMemory modules store conversational history to maintain contextual continuity across multi-turn interactions.\\nDevelopers can define custom tools using decorators and structured input-output validation mechanisms.\\nLangChain supports integration with cloud providers, open-source models, and enterprise deployment environments.\\nThe framework encourages modular design patterns that improve maintainability and scalability in production-grade ＡＩ applications.\\n\\nDatabricks is a unified analytics platform built on Apache Spark for distributed large-scale data processing.\\nIts primary purpose is enabling organizations to process massive datasets efficiently across clustered computing environments.\\nThe platform integrates data engineering, data science, and machine learning within a collaborative workspace.\\nDelta Lake enhances reliability by providing ACID transactions on top of cloud-based object storage systems.\\nUsers can develop notebooks collaboratively, combining code, visualizations, and documentation in a single workspace.\\nStructured streaming and batch pipelines can coexist within the same scalable processing infrastructure.\\nUnity Catalog centralizes governance, metadata management, and fine-grained access control policies.\\nWorkflows automate recurring jobs, ensuring dependable orchestration of enterprise data pipelines.\\nDatabricks supports medallion architecture patterns including Bronze, Silver, and Gold layers for data refinement.\\nThe platform bridges big data engineering with advanced artiﬁcial intelligence and analytics initiatives.\\n\\nMachine learning is a branch of artiﬁcial intelligence focused on enabling systems to learn patterns from data.\\nThe purpose of machine learning is allowing computers to improve performance without explicit rule-based programming.\\nSupervised learning uses labeled datasets to train predictive models for classification or regression tasks.\\nUnsupervised learning identifies hidden structures or clusters in data without predefined labels.\\nReinforcement learning trains agents through reward signals that guide long-term decision-making strategies.\\nModel development requires splitting data into training, validation, and testing subsets carefully.\\nFeature engineering transforms raw inputs into meaningful numerical representations for model training.\\nOverﬁtting occurs when a model memorizes training examples instead of generalizing effectively.\\nEvaluation metrics such as precision, recall, and accuracy measure predictive model performance.\\nMachine learning supports practical use cases including recommendation engines, fraud detection, and demand forecasting.\\n\\nA database management system is software designed to store, organize, and retrieve structured information efficiently.\\nThe main purpose of a DBMS is ensuring consistency, durability, and secure multi-user access to data.\\nRelational database systems structure data into tables composed of rows and columns with defined relationships.\\nStructured Query Language, commonly called SQL, enables users to manipulate and query stored records effectively.\\nTransaction management enforces ACID properties to guarantee reliable processing even during unexpected failures.\\nIndexing mechanisms accelerate data retrieval by reducing the amount of scanned information.\\nConcurrency control techniques prevent conflicts when multiple transactions access the same dataset simultaneously.\\nBackup and recovery procedures protect organizations from accidental deletion or hardware malfunctions.\\nModern database systems include distributed, cloud-native, and NoSQL architectures for scalability.\\nDatabase management solutions power applications ranging from financial systems to large-scale e-commerce platforms.\\n\\nAgentic AI systems can automate customer support operations by interpreting intent and responding appropriately.\\nThese intelligent agents analyze context before selecting suitable actions from multiple possible alternatives.\\nTask-oriented agents follow structured workﬂow definitions while still adapting dynamically to new conditions.\\nConversational agents focus primarily on dialogue management and maintaining coherent contextual understanding.\\nResearch-oriented agents gather information from multiple sources and summarize findings efficiently.\\nPlanning agents break down complex objectives into smaller executable subtasks before taking action.\\nTool-using agents integrate with search engines, calculators, and enterprise APIs seamlessly.\\nMulti-agent systems allow specialization, where each agent handles a specific responsibility within collaboration.\\nThe purpose of these systems is increasing productivity while minimizing repetitive manual supervision.\\nThe “agentic” design philosophy emphasizes autonomy, adaptability, and goal-directed intelligent behavior.\\n\\nLangChain-based agents combine reasoning capabilities with structured tool selection mechanisms for dynamic workflows.\\nThey interpret user prompts carefully before deciding whether to call a database, API, or retriever.\\nRetrieval-Augmented Generation connects vector embeddings with language models for contextual answer generation.\\nVector databases store numerical embeddings that represent semantic meaning of text passages.\\nCosine similarity measures the closeness between embedding vectors within high-dimensional space.\\nPrompt templates standardize instructions to ensure consistent response formatting across multiple queries.\\nOutput parsers validate structured responses, improving reliability in automated decision pipelines.\\nMemory components store intermediate reasoning steps for multi-turn conversational applications.\\nDevelopers configure chains declaratively or programmatically depending on architectural requirements.\\nLangChain simplifies building production-ready AI orchestration layers that integrate models, memory, and tools effectively.\\n\\nDatabricks supports the entire machine learning lifecycle from experimentation to deployment and monitoring.\\nMLflow within Databricks tracks experiments, parameters, and metrics in a centralized repository.\\nFeature stores manage reusable engineered features that ensure consistency across training and inference stages.\\nDistributed training leverages cluster computing resources to accelerate large-scale model development.\\nAutoML capabilities help beginners create baseline predictive models with minimal manual configuration.\\nModel serving endpoints deploy trained models for real-time or batch inference workloads.\\nIntegration with cloud storage enables scalable ingestion of structured and unstructured datasets.\\nSecurity features implement role-based access control and data encryption standards comprehensively.\\nCollaborative notebooks promote team-based experimentation, documentation, and reproducible analytics processes.\\nThe platform effectively combines big data processing, governance, and advanced artiﬁcial intelligence solutions.\\n')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader(\"../data/dataengineering.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b30163c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "chunks = splitter.split_documents(documents)\n",
    "#chunks_str = [chunk.page_content for chunk in chunks]\n",
    "#chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db39dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(dotenv_path=\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c59020",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "#embedded_chunks = embedding.embed_documents(chunks_str)\n",
    "#embedded_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "920813a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma DB directory already exists.\n",
      "Existing Collections: ['data_engineering', 'langchain']\n",
      "Deleted existing collection: data_engineering\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"../chroma_db\"):\n",
    "    os.makedirs(\"../chroma_db\")\n",
    "    print(\"Chroma DB directory created.\")\n",
    "else:\n",
    "    print(\"Chroma DB directory already exists.\")\n",
    "\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"../chroma_db\")\n",
    "existing_collections = [c.name for c in client.list_collections()]\n",
    "print(f\"Existing Collections: {existing_collections}\")\n",
    "\n",
    "COLLECTION_NAME = \"data_engineering\"\n",
    "\n",
    "if COLLECTION_NAME in existing_collections:\n",
    "    client.delete_collection(COLLECTION_NAME)\n",
    "    print(f\"Deleted existing collection: {COLLECTION_NAME}\")\n",
    "else:\n",
    "    print(\"Collection does not exist. Creating new one.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aade382d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Document(id='073da520-18fc-4184-9223-b8d5e81e79db', metadata={'source': '../data/dataengineering.txt'}, page_content='Machine learning is a branch of artiﬁcial intelligence focused on enabling systems to learn patterns from data.\\nThe purpose of machine learning is allowing computers to improve performance without explicit rule-based programming.\\nSupervised learning uses labeled datasets to train predictive models for classification or regression tasks.'), 0.8394509553909302)\n",
      "(Document(id='93778f82-a22a-43b1-9e19-72577c9d0785', metadata={'source': '../data/dataengineering.txt'}, page_content='Machine learning is a branch of artiﬁcial intelligence focused on enabling systems to learn patterns from data.\\nThe purpose of machine learning is allowing computers to improve performance without explicit rule-based programming.\\nSupervised learning uses labeled datasets to train predictive models for classification or regression tasks.'), 0.8394509553909302)\n",
      "(Document(id='780f7b1f-4ea2-4e29-ae12-f2ecdb87cb57', metadata={'source': '../data/dataengineering.txt'}, page_content='Unsupervised learning identifies hidden structures or clusters in data without predefined labels.\\nReinforcement learning trains agents through reward signals that guide long-term decision-making strategies.\\nModel development requires splitting data into training, validation, and testing subsets carefully.'), 1.0058438777923584)\n"
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding,\n",
    "    persist_directory=\"../chroma_db\",\n",
    "    collection_name=COLLECTION_NAME\n",
    ")\n",
    "\n",
    "results = vectorstore.similarity_search_with_score(\"what are the types of machine learning?\", k=3)\n",
    "\n",
    "for i in results:\n",
    "    print(i)\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8423d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2eb1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant.\n",
    "Answer the question using ONLY the context below. if you don't find answer in context, say I don't know\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f01a8146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know\n"
     ]
    }
   ],
   "source": [
    "question = \"what is the benefit of systemetic search?\"\n",
    "response = rag_chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e095f51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
